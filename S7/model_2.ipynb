{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"icT72j1kizVg","executionInfo":{"status":"ok","timestamp":1710402606917,"user_tz":-60,"elapsed":7260,"user":{"displayName":"Arun Kutty","userId":"09223495942040897754"}}},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"markdown","metadata":{"id":"J5pyHCqx8FQd"},"source":["Target:\n","\n","    Add rotation of around 15 degrees for better variation.\n","    Add a dropout value of 0.1\n","    Results:\n","        Parameters: 13.8k\n","        Best Train Accuracy: 89.07\n","        Best Test Accuracy: 99.40 (14th epoch)\n","    Analysis:\n","        The model is underfitting now\n","        The test accuracy is not that high, which means the network has more capacity to be trained properly .\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"V8R9hzsLIoSi","executionInfo":{"status":"ok","timestamp":1710403245604,"user_tz":-60,"elapsed":2,"user":{"displayName":"Arun Kutty","userId":"09223495942040897754"}}},"outputs":[],"source":["dropout_value = 0.1\n","class Net2(nn.Module):\n","    def __init__(self):\n","        super(Net2, self).__init__()\n","        # Input Block\n","        self.convblock1 = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(16),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 26\n","\n","        # CONVOLUTION BLOCK 1\n","        self.convblock2 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(32),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 24\n","\n","        # TRANSITION BLOCK 1\n","        self.convblock3 = nn.Sequential(\n","            nn.Conv2d(in_channels=32, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n","        ) # output_size = 24\n","        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 12\n","\n","        # CONVOLUTION BLOCK 2\n","        self.convblock4 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(16),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 10\n","        self.convblock5 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(16),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 8\n","        self.convblock6 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(16),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 6\n","        self.convblock7 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(16),\n","            nn.Dropout(dropout_value)\n","        ) # output_size = 6\n","\n","        # OUTPUT BLOCK\n","        self.gap = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=6)\n","        ) # output_size = 1\n","\n","        self.convblock8 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_value)\n","        )\n","\n","\n","        self.dropout = nn.Dropout(dropout_value)\n","\n","    def forward(self, x):\n","        x = self.convblock1(x)\n","        x = self.convblock2(x)\n","        x = self.convblock3(x)\n","        x = self.pool1(x)\n","        x = self.convblock4(x)\n","        x = self.convblock5(x)\n","        x = self.convblock6(x)\n","        x = self.convblock7(x)\n","        x = self.gap(x)\n","        x = self.convblock8(x)\n","\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x, dim=-1)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}